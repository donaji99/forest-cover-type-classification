# forest-cover-type-classification
Multiclass classification of forest cover types using K-Nearest Neighbors and Decision Tree algorithms. This project compares the performance of both models, analyzes their outcomes, and includes visualizations. Based on the U.S. Forest Service dataset

# üå≤ Forest Cover Type Classification: KNN vs Decision Tree  
### Clasificaci√≥n del tipo de cobertura forestal: KNN vs √Årbol de Decisi√≥n

## üìå Project Overview / Descripci√≥n del Proyecto

**English:**  
This project compares two classification models‚ÄîK-Nearest Neighbors (KNN) and Decision Tree‚Äîto predict the forest cover type based on cartographic and environmental features. It was developed as a second partial project for a data science course, aiming to evaluate performance differences between the two models on a multi-class dataset.

**Espa√±ol:**  
Este proyecto compara dos modelos de clasificaci√≥n‚ÄîK Vecinos m√°s Cercanos (KNN) y √Årbol de Decisi√≥n‚Äîpara predecir el tipo de cobertura forestal a partir de caracter√≠sticas cartogr√°ficas y ambientales. Fue desarrollado como proyecto del segundo parcial de un curso de ciencia de datos, con el objetivo de evaluar el rendimiento de ambos modelos en un conjunto de datos multiclase.

## üîó Dataset

- **Source / Fuente:** [Kaggle - Forest Cover Type Prediction](https://www.kaggle.com/competitions/forest-cover-type-prediction/data)  
- The dataset contains over 500,000 entries and 50+ columns.

## üìä Dataset Description / Descripci√≥n del Conjunto de Datos

**English:**  
The DataFrame includes topographical features such as `Elevation`, `Aspect`, and `Slope`, hydrological and roadway distances (`Horizontal_Distance_To_Hydrology`, `Horizontal_Distance_To_Roadways`), and hillshade indices like `Hillshade_9am`. It also contains binary indicators for wilderness areas and soil types (`Wilderness_Area1`, `Soil_Type1`, etc.), as well as the target variable `Cover_type`. Most columns are numerical (`int64`), and the target variable represents forest cover categories.

**Espa√±ol:**  
El DataFrame incluye caracter√≠sticas topogr√°ficas como `Elevation` (Elevaci√≥n), `Aspect` (Orientaci√≥n) y `Slope` (Pendiente), distancias hidrol√≥gicas y a carreteras (`Horizontal_Distance_To_Hydrology`, `Horizontal_Distance_To_Roadways`) e √≠ndices de sombreado como `Hillshade_9am`. Tambi√©n contiene indicadores binarios para √°reas silvestres y tipos de suelo (`Wilderness_Area1`, `Soil_Type1`, etc.), as√≠ como la variable objetivo `Cover_type`. La mayor√≠a de las columnas son num√©ricas (`int64`) y la variable objetivo representa las categor√≠as de cobertura forestal.

## üßπ Preprocessing / Preprocesamiento

**English:**  
The columns `Unnamed: 0`, `Unnamed: 1`, and `Unnamed: 2` were removed because they did not contain meaningful information for the analysis. These columns were artifacts from the original file (likely indexes or unlabelled values) and were not related to the actual features of the dataset.

**Espa√±ol:**  
Se eliminaron las columnas `Unnamed: 0`, `Unnamed: 1` y `Unnamed: 2` porque no conten√≠an informaci√≥n relevante para el an√°lisis. Estas columnas eran artefactos del archivo original (probablemente √≠ndices o valores sin contexto) y no estaban relacionadas con las caracter√≠sticas reales del conjunto de datos.

## üß™ Models and Evaluation / Modelos y Evaluaci√≥n

### ‚úÖ K-Nearest Neighbors (KNN)

- GridSearch was used to find the optimal value of `k`.
- The best value found was `k = X` (reemplaza con tu resultado).
- Accuracy: **0.5820**

### üå≥ Decision Tree Classifier

- Trained with default parameters.
- Accuracy: **0.9092**

### üìà Metrics Compared / M√©tricas Comparadas

- Accuracy
- Precision
- Recall
- F1-Score
- Classification Report
- Confusion Matrix

## üß† Conclusion / Conclusi√≥n

**English:**  
The Decision Tree model achieved a significantly higher accuracy (0.9092) compared to the K-Nearest Neighbors model (0.5820). Additionally, the decision tree showed better precision, recall, and f1-score values in almost all classes.

This may be because decision trees better handle non-linear relationships and complex hierarchical structures in the data, while KNN can be negatively affected by variable scale and noisy or unrepresentative nearby instances.

**Espa√±ol:**  
El modelo de √Årbol de Decisi√≥n obtuvo una exactitud significativamente mayor (0.9092) en comparaci√≥n con el modelo de K Vecinos m√°s Cercanos (0.5820). Adem√°s, el √°rbol de decisi√≥n present√≥ mejores valores en precisi√≥n, recall y f1-score en casi todas las clases.

Esto puede deberse a que los √°rboles de decisi√≥n se adaptan mejor a relaciones no lineales y a estructuras jer√°rquicas complejas en los datos, mientras que KNN puede verse afectado negativamente por la escala de las variables y la cantidad de ruido o datos poco representativos en sus vecinos m√°s cercanos.

## üõ†Ô∏è Requirements

To run this project, install the dependencies using:

```bash
pip install -r requirements.txt
